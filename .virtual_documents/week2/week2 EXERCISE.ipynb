


import os
import json
from dotenv import load_dotenv
from openai import OpenAI
import google.generativeai
import anthropic
import ollama
import gradio as gr


MODEL_GPT = 'gpt-4o-mini'
MODEL_LLAMA = 'llama3.2'
MODEL_ANTHROPIC = 'claude-3-haiku-20240307'
MODEL_GEMINI = 'gemini-2.0-flash-exp'


load_dotenv(override=True)
openai_api_key = os.getenv('OPENAI_API_KEY')
anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')
google_api_key = os.getenv('GOOGLE_API_KEY')

if openai_api_key:
    print(f"OpenAI API Key exists and begins {openai_api_key[:8]}")
else:
    print("OpenAI API Key not set")
    
if anthropic_api_key:
    print(f"Anthropic API Key exists and begins {anthropic_api_key[:7]}")
else:
    print("Anthropic API Key not set")

if google_api_key:
    print(f"Google API Key exists and begins {google_api_key[:8]}")
else:
    print("Google API Key not set")


openai = OpenAI()

claude = anthropic.Anthropic()

google.generativeai.configure()


#Prompt del sistema
system_prompt = "Eres un experto en LLM, inteligencia artificial y python \
el cual se le van a proporcionar una o varias preguntas técnicas relacionadas a los temas a los que eres experto \
y tienes que responder de tal manera que un estudiante que es muy novato y apenas está aprendiendo entienda"
system_prompt += "Siempre se preciso. si no sabes la respuesto, dilo."


# here is the question; type over this to ask something new
question = """
Por favor explica que hace este código y porque:
yield from {book.get("author") for book in books if book.get("author")}
"""


def chat(message, history):
    messages = [{"role": "system", "content": system_prompt}] + history + [{"role": "user", "content": message}]
    response = openai.chat.completions.create(model=MODEL_GPT, messages=messages)
    return response.choices[0].message.content
gr.ChatInterface(fn=chat, type="messages").launch()



import base64
from io import BytesIO
from PIL import Image



def artist(city):
    image_response = openai.images.generate(
            model="dall-e-3",
            prompt=f"",
            size="1024x1024",
            n=1,
            response_format="b64_json",
        )
    image_base64 = image_response.data[0].b64_json
    image_data = base64.b64decode(image_base64)
    return Image.open(BytesIO(image_data))



#image = artist("New York City")
#display(image)


import tempfile
import subprocess
from io import BytesIO
from pydub import AudioSegment
import time

def play_audio(audio_segment):
    temp_dir = tempfile.gettempdir()
    temp_path = os.path.join(temp_dir, "temp_audio.wav")
    try:
        audio_segment.export(temp_path, format="wav")
        time.sleep(3) # Student Dominic found that this was needed. You could also try commenting out to see if not needed on your PC
        subprocess.call([
            "ffplay",
            "-nodisp",
            "-autoexit",
            "-hide_banner",
            temp_path
        ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    finally:
        try:
            os.remove(temp_path)
        except Exception:
            pass
 
def talker(message):
    response = openai.audio.speech.create(
        model="tts-1",
        voice="onyx",  # Also, try replacing onyx with alloy
        input=message
    )
    audio_stream = BytesIO(response.content)
    audio = AudioSegment.from_file(audio_stream, format="mp3")
    play_audio(audio)

talker("Hola")


def response_gpt(history):
    messages = [{"role": "system", "content": system_prompt}] + history
    response = openai.chat.completions.create(
        model=MODEL_GPT,
        messages=messages,
        #stream=True
    )
    result = response.choices[0].message.content
    return result
    #for chunk in stream:
        #result += chunk.choices[0].delta.content or ""
        #yield result


def response_claude(history):
    result = claude.messages.create(
        model=MODEL_ANTHROPIC,
        max_tokens=1000,
        temperature=0.7,
        system=system_prompt,
        messages=history,
    )

    response = result.content[0].text
    return response
    #response = ""
    #with result as stream:
        #for text in stream.text_stream:
            #response += text or ""
            #yield response


def response_model(history, model):
    result = ''
    if model=="GPT":
        result = response_gpt(history)
    elif model=="Claude":
        result = response_claude(history)
    #elif model=="Gemini":
        #result = stream_gemini(prompt)
    else:
        raise ValueError("Unknown model")
    return result
    #yield from result


def chat(history, model):
    image = None
        
    reply = response_model(history, model)
    history += [{"role":"assistant", "content":reply}]

    # Comment out or delete the next line if you'd rather skip Audio for now..
    talker(reply)
    
    return history, image


chat([
    {"role": "user", "content": "first user prompt here"},
    {"role": "assistant", "content": "the assistant's response"},
    {"role": "user", "content": "the new user prompt"},
], "Claude")


with gr.Blocks() as ui:
    with gr.Row():
        chatbot = gr.Chatbot(height=500, type="messages")
        image_output = gr.Image(height=500)
    with gr.Row():
        entry = gr.Textbox(label="Chat with our AI Assistant:" , scale=3)
        model = gr.Dropdown(choices = ["GPT", "Claude", "Llama"], label="Select model",  value="GPT",   scale=1)
    with gr.Row():
        clear = gr.Button("Clear")

    def do_entry(message, history, selection):
        history += [{"role": "user", "content": f"{message} (Selección: {selection})"}]
        return "", history

    entry.submit(do_entry, inputs=[entry, chatbot, model], outputs=[entry, chatbot]).then(
        chat, inputs=[chatbot, model], outputs=[chatbot, image_output]
    )
    clear.click(lambda: None, inputs=None, outputs=chatbot, queue=False)

ui.launch(inbrowser=True)



